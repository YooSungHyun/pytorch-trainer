{
    "name": "torch-trainer: fsdp",
    "type": "python",
    "request": "launch",
    "module": "torch.distributed.run",
    "cwd": "${workspaceFolder}/pytorch-trainer",
    "console": "integratedTerminal",
    "justMyCode": false,
    "subProcess": true,
    "env": {
        "WANDB_DISABLED": "true",
        "CUDA_VISIBLE_DEVICES": "0,1,2,3",
        "TOKENIZERS_PARALLELISM":"false",
        "OMP_NUM_THREADS": "16",
        "WANDB_PROJECT":"torch-trainer",
        "WANDB_ENTITY":"",
        "WANDB_NAME":"fsdp(1;fp16)-lstm",
        "TRANSFORMERS_NO_ADVISORY_WARNINGS": "true"
    },
    "args": [
        "--master_port=25111",
        "--nproc_per_node=4",
        "fsdp_train.py",
        "--transformers_model_name=roberta-base",
        "--output_dir=fsdp_outputs/",
        "--seed=42",
        "--num_workers=12",
        "--per_device_train_batch_size=16",
        "--per_device_eval_batch_size=16",
        "--accumulate_grad_batches=1",
        "--max_epochs=5",
        "--learning_rate=2e-5",
        "--weight_decay=0.01",
        "--warmup_ratio=0.01",
        "--div_factor=10",
        "--final_div_factor=10",
        "--dataloader_drop_last=False",
        "--sampler_shuffle=True",
        "--log_every_n=1",
        "--group_by_length=True",
        "--model_dtype=bf16",
        "--metric_on_cpu=false"
    ]
}